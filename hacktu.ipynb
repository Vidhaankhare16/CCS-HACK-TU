{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1884733,"sourceType":"datasetVersion","datasetId":1005974},{"sourceId":253491,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":216778,"modelId":238488}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.layers import (\n    Dense, Dropout, GlobalAveragePooling2D,\n    BatchNormalization, Input\n)\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\ndef load_dataset(train_dir, val_dir, test_dir, batch_size=32, img_size=(300, 300)):\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        brightness_range=[0.9, 1.1],\n        fill_mode=\"nearest\"\n    )\n\n    val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n    train_ds = train_datagen.flow_from_directory(\n        train_dir, target_size=img_size,\n        batch_size=batch_size, class_mode=\"binary\"\n    )\n\n    val_ds = val_test_datagen.flow_from_directory(\n        val_dir, target_size=img_size,\n        batch_size=batch_size, class_mode=\"binary\"\n    )\n\n    test_ds = val_test_datagen.flow_from_directory(\n        test_dir, target_size=img_size,\n        batch_size=batch_size, class_mode=\"binary\"\n    )\n\n    return train_ds, val_ds, test_ds\n\ndef build_model(input_shape=(300, 300, 3)):\n    inputs = Input(shape=input_shape)\n    \n    base_model = InceptionResNetV2(\n        include_top=False,\n        weights=\"imagenet\",\n        input_tensor=inputs\n    )\n    \n    # Freeze base model first\n    base_model.trainable = False\n    \n    # Unfreeze last 150 layers for fine-tuning\n    for layer in base_model.layers[-150:]:\n        layer.trainable = True\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n\n    # Reduced regularization\n    x = Dense(1024, activation='swish', kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n\n    x = Dense(512, activation='swish', kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n\n    x = Dense(256, activation='swish')(x)\n    x = BatchNormalization()(x)\n\n    outputs = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model(inputs, outputs)\n    return model\n\n# Dataset paths\ntrain_dir = \"/kaggle/input/railway-track-fault-detection/Railway Track fault Detection Updated/Train\"\nval_dir = \"/kaggle/input/railway-track-fault-detection/Railway Track fault Detection Updated/Validation\"\ntest_dir = \"/kaggle/input/railway-track-fault-detection/Railway Track fault Detection Updated/Test\"\n\nbatch_size = 32\nimg_size = (300, 300)\n\ntrain_ds, val_ds, test_ds = load_dataset(train_dir, val_dir, test_dir, batch_size, img_size)\n\n# Callbacks\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2, min_lr=1e-6)\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n\nmodel = build_model()\noptimizer = AdamW(learning_rate=0.0001, weight_decay=0.0001)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=100,\n    callbacks=[reduce_lr, early_stopping]\n)\n\n# Evaluation\nloss, accuracy = model.evaluate(test_ds)\nprint(f\"Test Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# Save model\nmodel.save('/kaggle/working/model1.keras')\n\n# Visualization functions remain the same\nplot_training_curves(history)\nplot_confusion_matrix(model, test_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:16:45.156184Z","iopub.execute_input":"2025-02-08T21:16:45.156437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n\nmodel = load_model('/kaggle/working/model1.keras')\n\ninference_dir = \"/path/to/your/inference/images\"\n\nimg_size = (300, 300)\n\ndef preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=img_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    return img_array\n\npredictions = []\n\nfor img_name in os.listdir(inference_dir):\n    img_path = os.path.join(inference_dir, img_name)\n    \n    img_array = preprocess_image(img_path)\n    \n    prediction = model.predict(img_array)\n    predictions.append((img_name, prediction[0][0]))\n    \nfor img_name, pred in predictions:\n    print(f\"Image: {img_name}, Prediction: {'Faulty' if pred > 0.5 else 'Normal'} (Score: {pred:.4f})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}